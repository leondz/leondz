### Hi there ğŸ‘‹

- ğŸ”­ I research natural language processing and machine learning. I'm currently looking at:
  - ğŸ”’ **LLM security:** hazards manifest if we don't treat language models as unreliable and subvertible. Or as [demons](https://www.summonademonandbind.it/)!
  - ğŸ›¡ï¸ **Online harms:** content safety, illegal information, CBRN risks and more.  [Enumerate risks with Language Model Risk Cards](https://arxiv.org/abs/2303.18190)
<!--  - ğŸŒ± **Efficient machine learning:** we should be able to do more with much less than we have; always interested in data efficiency and greener, smaller, faster ğŸš€, coarser models. Read our [survey on efficient NLP in TACL](https://arxiv.org/abs/2209.00099)! -->
<!--  - âœï¸ **Generation:** Creating meaningful sequences from a set of items is hard! See our [ICML paper on set2seq methods and the catalog problem](https://openreview.net/forum?id=xgFfr5IIuXP) -->
<!--  - ğŸ‡©ğŸ‡° **NLP for Danish:** I started and run [the Danish Gigaword project](https://gigaword.dk) -->
<!--  - ğŸ¥¼ **Clinical NLP:** how can we process medical records to, eventually, improve health outcomes -->

- ğŸ¢ I'm principal research scientist at [NVIDIA](https://www.nvidia.com/en-us/) for my day job, principal investigator of [StrÃ¸mberg NLP](https://stromberg.ai/) at [ITU Copenhagen](https://en.itu.dk) by night

- ğŸ§‘â€ğŸ“ Iâ€™m *still* learning [sizecoding](http://www.sizecoding.org/wiki/Main_Page)

- ğŸ“ My research papers are on [Google Scholar](https://scholar.google.dk/citations?user=d8iwqa8AAAAJ&hl=en). Ask me about any of them!

- ğŸª¶ I write NLP, machine learning, and language tech articles on my blog, [Inter Human Agreement](https://interhumanagreement.substack.com/)
